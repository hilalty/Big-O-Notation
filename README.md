Big O notation is a tool used to measure the complexity or efficiency of algorithms. 

It tells us how the time it takes for an algorithm to run, changes as the size of the input changes. It's represented by a mathematical function. 

How long an algorithm takes to run tells about time complexity and how much memory is used by an algorithm tells about space complexity. 

- O refers to the order of the function, or its growth rate
- n is the length of the array to be sorted. 

It can take different values with different powers like; 
constant O(1), 
logarithmic O(log n), 
linear O(n), 
linearithmic O(n log n), 
quadratic O(n^2), 
cubic O(n^3), 
exponential O(2^n).